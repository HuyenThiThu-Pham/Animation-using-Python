{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenThiThu-Pham/Animation-using-Python/blob/main/Assignment_1_Data_Wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "abh85gJfUV3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a77849-4435-44ca-b1ce-89147422100f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1_ Data Wrangling and Social Media Analytics\n",
        "\n",
        "[Link to the notebook](https://colab.research.google.com/drive/1Z1ug5_vxAKyvZexO0iMplJlGY28JK3PN#scrollTo=oOKLRDBrUIK8)\n",
        "\n",
        "\n",
        "\n",
        "## 1. An use case of social media analytics of Rebel Sport Company\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- [campaign brief](https://campaignbrief.com/rebel-unites-all-codes-in-new-football-is-everything-campaign-via-the-general-store/#:~:text=Inspired%20by%20rebel%27s%20commitment%20to,rebel%20as%20its%20true%20home.%E2%80%9D) -->\n",
        "\n",
        "### 1.1 Introduction\n",
        "\n",
        "Rebel Sport (Rebel) is a leading sporting goods retailer in Australia and New Zealand. They specialise in selling various sports equipment, clothing, footwear, and accessories for various sports and recreational activities.  Rebel Sport aims to cater to the needs of amateur and professional athletes and individuals who enjoy  an  active  lifestyle.  \n",
        "\n",
        "Rebel Sport started it operation way back in the year 1985 and has grown out to be the biggest retailer in sporting products for the country. In February 2025, Rebel Sport ranking top 3 website ranking for sport retailer in Australia. [most visted sport website](https://www.similarweb.com/top-websites/australia/sports/sports/). Social media can be said to be one of the most trending things and trending technology that is\n",
        "being used by many of the business organization (Siamagka et al. 2015). Social media has a huge influence over the operational activities of the company. It can be said that the firm uses the social media\n",
        "platform for managing, communication, coordinating, advertising and promoting purposeleverages real-time social media analytics to monitor and analyze customer sentiment and preferences.\n",
        "According to [Gorilla](https://gorilla360.com.au/blog/how-rebel-sport-uses-facebook/), Rebel Sport utilizes real-time social media analytics to monitor customer sentiment and preferences and to reach out to more number of customers and persuade them to buy and avail their goods and services and to persuade them regarding the quality of their product and service (Cook, 2017).\n",
        "\n",
        "\n",
        "\n",
        "By monitoring social media engagement such as tracking likes, shares, and comments on platforms like YouTube, Facebook, and Instagram, they can use AI-powered tools to categorize audience responses as positive, neutral, or negative. Or observing the reach and usage of campaign-related hashtags such as #FootballIsEverything to gauge brand impact (Hashtag Tracking).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 1.2 Business Impact:\n",
        "Explain that this sentiment\n",
        "analysis allows Rebel to\n",
        "tailor promotions to current\n",
        "trends, increasing sales.\n",
        "\n",
        "According to Fuchs, (2014), social media networking is the future of modern business promotional activities. By analyzing customer interactions, comments, and feedback on their social media channels, Rebel Sport gains valuable insights into how their brand and campaigns are perceived.\n",
        "\n",
        "Particularly, Rebel Sport’s use of real-time sentiment analysis allows the company to\n",
        "\n",
        "- **Tailor promotions to match customer preferences**, ensuring ads highlight the most engaging products.\n",
        "- **Identify current trends**, allowing the company to optimize inventory and marketing strategies.\n",
        "- **Enhance customer engagement**, leading to increased online and in-store sales.\n",
        "\n",
        "This approach enables them to understand customer needs and preferences, allowing them to reach out to more number of customers and persuade them to buy and avail their goods and services and to persuade them regarding the quality of their product and service (Cook, 2017).\n",
        "\n",
        " According to research, brands that leverage sentiment analysis for personalized marketing can increase revenue by up to 10% ([McKinsey & Company](https://www.mckinsey.com/)).\n",
        "\n",
        "\n",
        "### 1.3 Use of Real Data:\n",
        "\n",
        "reach and usage of campaign-related hashtags such as #FootballIsEverything to gauge brand impact\n",
        "One of Rebel’s most successful campaigns, Sport is Calling is one of Rebel's most successful campaigns.\n",
        "\n",
        "![Sport is Calling](https://www.rebelsport.com.au/sport-is-calling?srsltid=AfmBOor3Sbc3_TYNAyW0N8reFHhTStZ5RdGI0zv3LjoAQ8dF6XdiiPrm)\n",
        "\n",
        "\n",
        "While the initial launch was in 2020, Rebel Sport has iterated and relaunched the campaign, building upon the established brand platform. A notable iteration was launched in July 2024, featuring [new films](https://lbbonline.com/news/rebel-demonstrates-the-transformational-power-of-sport-in-new-campaign-with-the-monkeys) showcasing the sporting journeys of individuals like outback grazier Brendan Cullen and Olympian Sinead Diver. This relaunch was strategically timed weeks ahead of the Paris Olympics to encourage Australian participation in sports.\n",
        "\n",
        "\n",
        "It's safe to say that the campaign was successful. It generated significant social media buzz, particularly on Instagram, with over 10,800 posts using the hashtag [#SportIsCalling](https://www.instagram.com/explore/search/keyword/?q=%23sportiscalling&hl=en). This surge in user-generated content boosted online visibility and brand awareness.\n",
        "\n",
        "Moreover, the campaign's focus on real-life stories and the transformative power of sport created an emotional connection with audiences, strengthening brand loyalty and affinity.\n",
        "\n",
        "With positive sentiment expressed across social media platforms. This contributed to a positive brand perception and reinforced Rebel Sport's position as a supporter of Australian sports. It's reasonable to assume that the campaign positively influenced Rebel Sport's sales and customer engagement, aligning with industry research indicating that personalization and emotional marketing drive revenue growth.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oOKLRDBrUIK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. App Feature Proposal: Rebel GearMatch\n",
        "\n",
        "\n",
        "The Rebel Sport app currently offers a range of features to enhance the customer experience, including:\n",
        "\n",
        "> - **Product browsing and purchasing:** Customers can easily browse the extensive product catalog, add items to their cart, and complete purchases securely within the app.\n",
        "\n",
        "> - **Store locator:** Users can quickly find the nearest Rebel Sport store using the app's store locator functionality.\n",
        "\n",
        "> - **Order tracking:** Customers can track the status of their orders and receive notifications on delivery updates.\n",
        "\n",
        "> - **Rebel Active club integration:** Members can access their account details, earn and redeem rewards, and receive personalized offers through the app.\n",
        "\n",
        "> - **Push notifications:** Users can opt-in to receive push notifications about new products, promotions, and events.\n",
        "\n",
        "\n",
        "While these features provide a solid foundation, there's an opportunity to further enhance the app's functionality and customer value by introducing a **Gear Comparison Tool.**\n",
        "\n",
        "\n",
        "**The Need for a Gear Comparison Tool:**\n",
        "\n",
        "Customers often face challenges when comparing similar products, especially when it comes to technical specifications, customer reviews, and social media buzz. They might need to navigate between multiple websites, product pages, and review platforms to gather the necessary information, which can be time-consuming and frustrating.\n",
        "\n",
        "A dedicated **Gear Comparison Tool** within the Rebel Sport app would address this need by providing a centralized platform for customers to compare products side-by-side, making informed purchase decisions based on a comprehensive set of data points.\n",
        "\n",
        "Concept:\n",
        "\n",
        "Rebel GearMatch is an interactive tool within the Rebel Sport app that allows customers to compare different products side-by-side, making informed purchase decisions based on features, specifications, customer reviews, and social media buzz.\n",
        "\n",
        "\n",
        "<!-- From Google Analytics's data, rebelsport.com.au's web traffic has decreased by 18.99% in February 2025 compared to January 2025. ![image](/content/GA.png). To enhance customer engagement and increase sales, Rebel could introduce a new app feature called Rebel GearMatch, which leverages real-time social media data to **recommend personalized sports product combinations** based on users’ preferences, fitness activities, and current trends.\n",
        " **Leveraging Rebel Sport's existing membership program, where customers often enjoy better prices and exclusive benefits, can significantly facilitate data collection and enhance the personalization capabilities of GearMatch.**\n",
        " -->\n",
        "\n",
        "\n",
        "### 2.2 Data Collection Strategy:\n",
        "\n",
        "1. **Product Catalog Integration:**\n",
        "\n",
        "> - Rebel GearMatch would seamlessly integrate with Rebel Sport's product catalog, pulling in product information such as features, specifications, pricing, images, and availability.\n",
        "\n",
        "> - This data would be used to populate the comparison tool and provide accurate product details for comparison.\n",
        "\n",
        "2. **Customer Reviews and Ratings:**\n",
        "\n",
        "> - The app would collect and display customer reviews and ratings for products, either directly from the Rebel Sport website or through integration with third-party review platforms.\n",
        "\n",
        "> - This data would provide valuable social proof and insights into customer experiences with different products.\n",
        "\n",
        "3. **Social Media Sentiment Analysis:**\n",
        "\n",
        "> - Rebel GearMatch would leverage social media listening tools to analyze conversations and sentiment related to specific products and brands.\n",
        "\n",
        "> - This data would provide an understanding of overall customer perception and identify popular or highly-rated products based on social media buzz.\n",
        "\n",
        "4. **User Preferences and Purchase History:**\n",
        "\n",
        "> - The app would utilize data from the Rebel Active club, purchase history, and in-app interactions to personalize product recommendations and comparisons.\n",
        "\n",
        "> - This data would help tailor the comparison experience to individual customer preferences and interests.\n",
        "\n",
        "\n",
        "<!-- **1. Data Collection**\n",
        "\n",
        "\n",
        "- **Social Media Integration**: With a high proportion of frequent Rebel Sport shoppers being members, GearMatch can readily access valuable purchase history, preferences, and engagement data through their membership accounts. Users can further enhance personalization by connecting their social media profiles (e.g., Instagram, Facebook, Strava) to the app, granting permission to analyze fitness-related posts, hashtags, likes, and tagged locations. This combined approach provides a comprehensive view of the customer's sporting interests and needs.\n",
        "\n",
        "- **In-App Behavior Data**: Rebel GearMatch will also track users’ in-app activity, including past purchases, search history, and engagement with specific promotions or product categories, such as football gear, running shoes, or gym accessories.\n",
        "\n",
        "**2. Real-Time Trend and Sentiment Analysis**\n",
        "\n",
        "The app uses machine learning and sentiment analysis algorithms to identify users’ sports interests (e.g., football, running, cycling) based on their social media interactions.\n",
        "It also tracks trending products and hashtags across social media platforms. For example, if a new running shoe becomes popular due to a marathon event, the app may prioritize that product in recommendations. It also tracks customised shopping experiences in real-time based on their online interactions. The recommendations appear on **Youtube, Instagram, Facebook ads, and the Rebel Sport website** when customers browse related products.\n",
        "\n",
        "\n",
        "***Product Recommendation Logic***\n",
        "\n",
        "Based on user data and real-time trends, Rebel GearMatch will offer personalized sports product combinations tailored to each user’s preferences, including:\n",
        "\n",
        "- Performance Gear Sets: For users posting about strength training, the app might recommend a package with weightlifting gloves, compression wear, and resistance bands.\n",
        "\n",
        "- Match Day Essentials: For football fans engaging with AFL or NRL hashtags, the app might suggest team jerseys, supporter gear, and hydration packs.\n",
        "\n",
        "- Running Kits: For users tracking runs on Strava, the app could recommend running shoes, moisture-wicking socks, and energy gels.\n",
        "\n",
        "Users will also have customization options, allowing them to adjust recommendations based on specific needs (e.g., budget, color preference, or eco-friendly products).\n",
        "\n",
        "**Customization Options:** Users can adjust recommendations based on budget, color preference, or eco-friendly products. -->\n",
        "\n",
        "### 2.3 Business Impact: Enhancing Customer Loyalty and Boosting Sales\n",
        "[Five strategies driven business](https://media.supercheapauto.com.au/corp/files/user/AGM2024/2024_Annual_Report.pdf) of Rebel Sport  are centered around: Growing the Brand, leveraging closeness to customer, connected omni-retail supply chain, simplify the business and excel in omni-retail.\n",
        "\n",
        "The proposed Gear Comparison Tool, Rebel GearMatch, aligns with these objectives and can significantly improve business performance in the following ways:\n",
        "\n",
        "\n",
        "\n",
        "**1. Increased Customer Loyalty**\n",
        "\n",
        "Any successful personalization effort hinges on the creation of messages and\n",
        "experiences offering a high degree of value to the customer. To determine\n",
        "what’s valuable we use a simple formula:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$$\n",
        " \\quad Value^* = \\frac{\\text{Relevance} + \\text{Timeliness}}{\\text{Loss of privacy}} \\text{Trust}\n",
        "$$\n",
        "$$^* \\text{to the customer}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Customers see value as a function of how relevant and timely a message is in relation to how much it “costs,” meaning how much personal information has to be shared\n",
        "and how much personal effort it takes to get it. Importantly, trust in the brand will boost\n",
        "overall value, though that can grow or recede over time, depending on the customer’s satisfaction with various interactions with the brand.\n",
        "\n",
        "Brand loyalty is what customers feel when they’re particularly drawn to specific companies. It’s the connection or pull that keeps them coming back to purchase again. It’s the feeling that compels them to become loyal advocates, recommending to family and friends without a second thought.\n",
        "\n",
        "These strong feelings are explained through a series of emotional, psychological, and positive associations. It’s often more intuitive than it is logical. And it’s because of how an interaction with a brand made someone feel, as opposed to just the widget they bought.\n",
        "\n",
        "A reported 61% of Generation Z consumers might start with an initial assessment about the quality of the product or service from a particular brand.3 However, then factors from the entire purchasing experience begin coming into play, including:\n",
        "\n",
        "\n",
        "[reference](https://www.business.reddit.com/learning-hub/articles/brand-loyalty)\n",
        "\n",
        "the service or interactions a consumer had,\n",
        "the perceived value in relation to price,\n",
        "how easy (or difficult) it was to work with a brand, and\n",
        "whether (or not) it seems like the brand is doing what’s “right” in the consumer’s view all play a part\n",
        "\n",
        "\n",
        "\n",
        "Personalized shopping experiences improve customer satisfaction and loyalty. According to Accenture, 91% of consumers are more likely to shop with brands that provide relevant offers and recommendations (Accenture, 2018). By leveraging membership data, GearMatch can further personalize recommendations, Rebel can create a more engaging and user-centric experience, fostering stronger relationships with loyal customers.\n",
        "\n",
        "**2. Increased Customer Engagement and Sales**\n",
        "\n",
        "By providing a centralized platform for product comparison, Rebel GearMatch can enhance customer engagement and drive sales. Research shows that personalized product recommendations can increase revenue by up to 10% (McKinsey & Company).\n",
        "\n",
        "\n",
        "Personalized product recommendations often lead to higher spending. According to [Predictive Intelligence Benchmark Report](https://brandcdn.exacttarget.com/sites/exacttarget/files/deliverables/etmc-predictiveintelligencebenchmarkreport.pdf), direct sales from predictive intelligence increase dramatically from 6.32% in months 10 to 12 to 9.60% in months 13 to 18.\n",
        " Research from McKinsey & Company shows that personalization can drive a 5-15% increase in revenue and a 10-30% boost in marketing efficiency (McKinsey & Company, 2020).\n",
        "\n",
        "\n",
        "\n",
        " On average, an intelligent recommender system delivers a 22.66% lift in conversions rates for web products.[nvidia](https://www.nvidia.com/en-us/glossary/recommendation-system/#).\n",
        "\n",
        " By bundling related sports items, Rebel GearMatch can encourage larger purchases, increasing the average order value.\n",
        "\n",
        " **3. Higher Average Purchase Values:** Personalized product recommendations often lead to higher spending. According to the Predictive Intelligence Benchmark Report, direct sales from predictive intelligence increase dramatically, leading to a 22.66% lift in conversion rates for web products (Nvidia).\n",
        "\n",
        "**4. Improved Customer Experience:** By simplifying the product research process and providing valuable insights, Rebel GearMatch enhances the overall customer experience, leading to increased customer satisfaction and positive brand perception.\n",
        "\n",
        "**5. Data-Driven Decision Making:** The data collected through Rebel GearMatch provides valuable insights into customer preferences and trends. This data can be used to inform product development, marketing strategies, and inventory management, leading to more effective business decisions.\n",
        "\n",
        "**6. Competitive Advantage:** By offering a unique and innovative feature like Rebel GearMatch, Rebel Sport can differentiate itself from competitors and attract new customers. This can strengthen their market position and drive further business growth.\n",
        "\n",
        "By aligning with Rebel Sport's core business objectives and leveraging data-driven insights, Rebel GearMatch has the potential to significantly improve customer engagement, loyalty, sales, and overall business performance. The evidence and numbers cited above demonstrate the positive impact that personalized shopping experiences and data-driven decision-making can have on retail businesses."
      ],
      "metadata": {
        "id": "qiO4sNTpG7_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Rebel GearMatch: An Innovative and useful App feature\n",
        "\n",
        "\n",
        "Rebel GearMatch, the proposed Gear Comparison Tool, presents a unique and innovative approach to enhancing the customer journey within the Rebel Sport app. By addressing a critical need for simplified product comparison, it stands to significantly benefit both Rebel Sport and its customers.\n",
        "\n",
        "Innovation and Usefulness:\n",
        "\n",
        "Centralized Comparison: Rebel GearMatch provides a centralized platform for customers to compare products side-by-side, eliminating the need to navigate multiple websites and product pages. This streamlines the research process, saving customers time and effort.\n",
        "Comprehensive Data Points: The tool incorporates a wide range of data points, including product features, specifications, customer reviews, and social media sentiment, providing customers with a holistic view of each product.\n",
        "Personalized Recommendations: By leveraging customer data and preferences, Rebel GearMatch delivers personalized product recommendations and comparisons, ensuring relevance and enhancing the customer experience.\n",
        "Social Proof and Validation: The integration of customer reviews and social media sentiment provides social proof and validation, helping customers make informed purchase decisions based on the experiences of others.\n",
        "Interactive and User-Friendly Interface: The tool is designed with an intuitive and interactive interface, making it easy for customers to navigate, compare products, and discover new options.\n",
        "Impact on Sales and Customer Experience:\n",
        "\n",
        "Increased Sales: Personalized product recommendations and comparisons have been shown to significantly increase sales. According to McKinsey & Company, personalization can drive a 5-15% increase in revenue.\n",
        "Enhanced Customer Experience: By simplifying the product research process and providing valuable insights, Rebel GearMatch enhances the overall customer experience, leading to increased satisfaction and positive brand perception. Studies by Accenture have shown that 91% of consumers are more likely to shop with brands that provide relevant offers and recommendations.\n",
        "Long-Term Loyalty: A positive customer experience fosters loyalty and repeat purchases. By delivering a valuable and personalized service through Rebel GearMatch, Rebel Sport can build stronger relationships with customers and encourage long-term loyalty. Research by Bain & Company indicates that a 5% increase in customer retention can lead to a 25-95% increase in profits.\n",
        "Evidence and Cited Studies:\n",
        "\n",
        "McKinsey & Company (2020): Personalization can drive a 5-15% increase in revenue.\n",
        "Accenture (2018): 91% of consumers are more likely to shop with brands that provide relevant offers and recommendations.\n",
        "Bain & Company: A 5% increase in customer retention can lead to a 25-95% increase in profits.\n",
        "By implementing Rebel GearMatch, Rebel Sport can demonstrate a commitment to innovation and customer-centricity, creating a valuable tool that enhances the customer experience, drives sales, and fosters long-term loyalty. The evidence and cited studies support the potential for significant positive impact on the business.\n"
      ],
      "metadata": {
        "id": "eUERQgvSNsaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Challenges of Implementing the Proposed Application\n",
        "\n",
        "\n",
        "Discuss the\n",
        "challenges of\n",
        "implementing the\n",
        "proposed\n",
        "application.\n",
        "\n",
        "First of all, most retailers are still in the early stages of their personalization efforts. Our research indicates that only 15 percent of retailers have fully implemented personalization strategies. More than 80 percent are still defining a personalization strategy or have begun pilot initiatives. The remaining retailers have decided to deprioritize personalization for now, for various reasons.\n",
        "\n",
        "Retailers seem to be facing four main tactical challenges in getting personalization off the ground:\n",
        "\n",
        "1. Data management. More than two-thirds of survey respondents (67 percent) indicate that their greatest personalization challenge is the gathering, integration, and synthesis of customer data.\n",
        "\n",
        "2. Data analytics. Acquiring and maintaining in-house expertise in analytics and data science are proving to be major concerns for 48 percent of surveyed retailers.\n",
        "\n",
        "3. Alignment of retail organizations across functions. For many retailers, siloed processes and organizational models prevent the efficient and prompt sharing of customer data and promotion decisions (for example, difficulty in aligning the marketing and merchandizing teams). Of the survey group, 43 percent say these silos “make life difficult,” and 25 percent report that such silos make it difficult to get vendor funding—as well as buy-in—from suppliers for personalized offerings (especially in the grocery category). In many cases, these sorts of changes require a significant shift in the mindsets of employees so that they become comfortable with the test-and-learn and fast-fail experiments that personalization requires.\n",
        "\n",
        "4. Tools and technology enablement. Of the survey participants, 67 percent admit that they did not have the correct tools in place to execute personalization at scale. An additional 41 percent say finding the right solution partner was a struggle.\n",
        "\n",
        "These challenges are further complicated by the fact that many retailers still operate under a hybrid, “bricks and clicks” strategy, making it even more difficult to implement the right levels of personalization in stores and online. Retailers with an omnichannel setup, however, have their own challenges, particularly in structuring offers and executing across communication touchpoints.\n",
        "### 4.3 Suggestions for Mitigation\n",
        "Suggest the implementation\n",
        "of robust protocols and\n",
        "obtaining explicit user\n",
        "consent for data use.\n",
        "\n",
        "\n",
        "An effective personalization operating model has four prongs: a data foundation, decisioning, design, and distribution (exhibit). Within this model are eight core elements."
      ],
      "metadata": {
        "id": "QUsWRhpCG62t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j5CuCb9pG6Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.A\n",
        "\n",
        "A good product for a good price is just the starting point. Most brand loyalty is further developed after that initial sale. And it’s often driven more by what a customer thinks of their experience, as opposed to what messaging brands are carefully broadcasting to the world.\n",
        "\n",
        "Start by getting direct access to customer insight\n",
        "The first step in developing brand loyalty starts with the customers’ own point of view, then, as opposed to a brand's products or offering.\n",
        "\n",
        "Reddit Pro is a perfect place to dive into the minds of customers. Their daily interactions are summarized across the 16 billion posts and comments.10 These first-hand accounts often divulge exactly what people are thinking, and Reddit Pro can help synthesize for you – sentiment and all."
      ],
      "metadata": {
        "id": "gVDMJ2x66dsh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opDJixAJ6crg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages:\n",
        "!pip install asyncpraw pandas nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C4phM4zLi98y",
        "outputId": "021cb5cf-dc1c-4689-f89c-534b8b704aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: asyncpraw in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: aiofiles<1 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.8.0)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (3.10.1)\n",
            "Requirement already satisfied: aiosqlite<=0.17.0 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.17.0)\n",
            "Requirement already satisfied: asyncprawcore<3,>=2.1 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (2.4.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.18.0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (4.0.3)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update-checker>=0.18->asyncpraw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries:\n",
        "import asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "import nest_asyncio\n",
        "\n",
        "# Allow nested event loops in Colab:\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Reddit API credentials:\n",
        "client_id = '_mEvCBQLeRsUrN5nmdcD6A'\n",
        "client_secret = 'ezp0D4hfMPO_jD2Sdd7xX16T_YKXvQ'\n",
        "user_agent = 'Confident-Ad8604'\n",
        "\n",
        "# Initialize async PRAW with API credentials:\n",
        "reddit = asyncpraw.Reddit(client_id=client_id,\n",
        "                          client_secret=client_secret,\n",
        "                          user_agent=user_agent)\n",
        "\n",
        "# Define the subreddit and the number of posts to fetch (1000, in this case):\n",
        "subreddit_name = 'ShoesForRunning'\n",
        "num_posts = 1000\n",
        "\n",
        "# Create function to fetch posts asynchronously:\n",
        "async def fetch_posts():\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    posts = []\n",
        "    async for post in subreddit.hot(limit=num_posts):\n",
        "        posts.append({\n",
        "            'title': post.title,\n",
        "            'score': post.score,\n",
        "            'id': post.id,\n",
        "            'url': post.url,\n",
        "            'num_comments': post.num_comments,\n",
        "            'created': post.created,\n",
        "            'body': post.selftext\n",
        "        })\n",
        "\n",
        "    # Convert the list of posts to a DataFrame:\n",
        "    df = pd.DataFrame(posts)\n",
        "\n",
        "\n",
        "    # Save the DataFrame to a CSV file (choose the pathway in your Google Drive):\n",
        "    #df.to_csv('/content/drive/MyDrive/Data Wrangling and Social Media Analytics Practice/reddit_posts.csv', index=False)\n",
        "    df.to_csv('reddit_posts.csv', index=False)\n",
        "\n",
        "    # Print a message to confirm the file was saved:\n",
        "    print(\"Posts have been saved to reddit_posts.csv\")\n",
        "\n",
        "# mount Google Drive to access it directly\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Run the async function:\n",
        "await fetch_posts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiqf-oR8sQEc",
        "outputId": "2d87411d-2ea2-414b-f977-624f38999138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Posts have been saved to reddit_posts.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "rfXt2lohSUy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required library:\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file:\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data Wrangling and Social Media Analytics Practice/reddit_posts.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame:\n",
        "print(df.head())\n",
        "\n",
        "### Handle missing values:\n",
        "\n",
        "# Check for missing values:\n",
        "print(\"Missing values before cleaning:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill missing values in 'body' with an empty string:\n",
        "df['body'].fillna('', inplace=True)\n",
        "\n",
        "# Remove rows with missing values in 'title' or 'created':\n",
        "df.dropna(subset=['title', 'created'], inplace=True)\n",
        "\n",
        "# Remove duplicate entries based on 'id':\n",
        "df.drop_duplicates(subset=['id'], inplace=True)\n",
        "\n",
        "# Verify missing values are handled:\n",
        "print(\"Missing values after cleaning:\\n\", df.isnull().sum())\n",
        "\n",
        "### Standardize text data:\n",
        "df['title'] = df['title'].str.lower()\n",
        "df['body'] = df['body'].str.lower()\n",
        "\n",
        "# Display results:\n",
        "print(\"Data after preprocessing:\\n\", df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC4kWAwu6Xha",
        "outputId": "18a53220-0f1e-4418-d273-ef469c13b819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  score       id  \\\n",
            "0                Ask Anything Monday - Weekly Thread      2  1epzfah   \n",
            "1                      How did you all learn python?     33  1eq0hkx   \n",
            "2  How much better is Pandas actually, and is it ...     88  1eplz5d   \n",
            "3            Paris 2024 Olympics Complete Medallists      2  1eq6w62   \n",
            "4  how to convert an answer from an input into Tr...      4  1epzwgj   \n",
            "\n",
            "                                                 url  num_comments  \\\n",
            "0  https://www.reddit.com/r/learnpython/comments/...             3   \n",
            "1  https://www.reddit.com/r/learnpython/comments/...            53   \n",
            "2  https://www.reddit.com/r/learnpython/comments/...            41   \n",
            "3  https://www.reddit.com/r/learnpython/comments/...             2   \n",
            "4  https://www.reddit.com/r/learnpython/comments/...             8   \n",
            "\n",
            "        created                                               body  \n",
            "0  1.723421e+09  Welcome to another /r/learnPython weekly \"Ask ...  \n",
            "1  1.723424e+09  I'm thinking of going into Cyber Operations in...  \n",
            "2  1.723386e+09  I've been working a lot recently with gatherin...  \n",
            "3  1.723445e+09  Hi! I'm looking to get the data of all the med...  \n",
            "4  1.723422e+09  hello question from someone that is just start...  \n",
            "Missing values before cleaning:\n",
            " title           0\n",
            "score           0\n",
            "id              0\n",
            "url             0\n",
            "num_comments    0\n",
            "created         0\n",
            "body            0\n",
            "dtype: int64\n",
            "Missing values after cleaning:\n",
            " title           0\n",
            "score           0\n",
            "id              0\n",
            "url             0\n",
            "num_comments    0\n",
            "created         0\n",
            "body            0\n",
            "dtype: int64\n",
            "Data after preprocessing:\n",
            "                                                title  score       id  \\\n",
            "0                ask anything monday - weekly thread      2  1epzfah   \n",
            "1                      how did you all learn python?     33  1eq0hkx   \n",
            "2  how much better is pandas actually, and is it ...     88  1eplz5d   \n",
            "3            paris 2024 olympics complete medallists      2  1eq6w62   \n",
            "4  how to convert an answer from an input into tr...      4  1epzwgj   \n",
            "\n",
            "                                                 url  num_comments  \\\n",
            "0  https://www.reddit.com/r/learnpython/comments/...             3   \n",
            "1  https://www.reddit.com/r/learnpython/comments/...            53   \n",
            "2  https://www.reddit.com/r/learnpython/comments/...            41   \n",
            "3  https://www.reddit.com/r/learnpython/comments/...             2   \n",
            "4  https://www.reddit.com/r/learnpython/comments/...             8   \n",
            "\n",
            "        created                                               body  \n",
            "0  1.723421e+09  welcome to another /r/learnpython weekly \"ask ...  \n",
            "1  1.723424e+09  i'm thinking of going into cyber operations in...  \n",
            "2  1.723386e+09  i've been working a lot recently with gatherin...  \n",
            "3  1.723445e+09  hi! i'm looking to get the data of all the med...  \n",
            "4  1.723422e+09  hello question from someone that is just start...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 1: Crawling and Scraping**"
      ],
      "metadata": {
        "id": "uhPJ2zdQF09x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Create a Reddit App:** Create a Reddit app and obtain the `client_id`, `client_secret`, and `user_agent`. Report each step and describe what each credential is used for.\n",
        "\n",
        "   1. **Log in to Reddit:**\n",
        "      - Go to [Reddit login page](https://www.reddit.com/login/) and log in with your Reddit account.\n",
        "      \n",
        "   2. **Access the Reddit App Preferences:**\n",
        "      - Navigate to the [Reddit App Preferences](https://www.reddit.com/prefs/apps) page.\n",
        "      - Scroll down to the section labeled \"Developed Applications\" and click on \"Create App\" or \"Create Another App.\"\n",
        "      \n",
        "   3. **Create a New Application:**\n",
        "      - Fill out the form with the following details:\n",
        "         - **Name:** Choose a name for your application (e.g., `RedditCrawlerApp`).\n",
        "         - **App type:** Select \"script\" as the application type.\n",
        "         - **Description:** Provide a brief description of your application (optional).\n",
        "         - **About URL:** You can leave this blank.\n",
        "         - **Redirect URI:** Enter `http://localhost:8000` (a placeholder URL).\n",
        "         - **Permissions:** You can leave the default settings as they are.\n",
        "      - Click on the \"Create app\" button to create your application.\n",
        "      \n",
        "   4. **Obtain Your Credentials:**\n",
        "      - After creating the app, you will see your app listed under \"Developed Applications.\" Click on your app's name to view its details.\n",
        "      - **client_id:** This is the unique identifier for your application. It is displayed just under the \"personal use script\" label.\n",
        "      - **client_secret:** This is the secret key used to authenticate your application. It is displayed next to the \"secret\" label.\n",
        "      - **user_agent:** This is a string that identifies your application to Reddit. You need to create a descriptive user agent (e.g., `MyRedditCrawler/0.1 by YourUsername`).\n",
        "\n",
        "**Description of Credentials:**\n",
        "\n",
        "- **client_id:** The client ID is a public identifier for your application. It is used to identify your application to Reddit's API. This ID is required for all API requests.\n",
        "- **client_secret:** The client secret is a confidential key used to authenticate your application. It should be kept private and never exposed in public repositories or shared with others. The client secret is used in combination with the client ID to securely access Reddit's API.\n",
        "- **user_agent:** The user agent is a string that identifies your application to Reddit. It should be unique and descriptive, including information such as your application name and version, and your Reddit username. The user agent helps Reddit understand who is making the requests and for what purpose."
      ],
      "metadata": {
        "id": "rUgyEJtzHL8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a script to fetch the top 1000 hot posts from the `learnpython` subreddit. Ensure your script saves the data to a CSV file. Describe each step of the process, including initializing the Reddit API client and handling the fetched data.\n",
        "\n",
        "Steps:\n",
        "- Install Required Libraries: Ensure asyncpraw, pandas, and nest_asyncio are installed.\n",
        "- Initialize PRAW: Set up the Reddit API credentials and initialize the asyncpraw.Reddit object.\n",
        "- Fetch Posts: Define an asynchronous function to fetch posts from the specified subreddit and store them in a list.\n",
        "- Convert to DataFrame and Save: Convert the list of posts to a Pandas DataFrame and save it to a CSV file.\n",
        "- Verify Data: Load the saved CSV file and print the first few rows to verify the data was saved correctly."
      ],
      "metadata": {
        "id": "5THnjj4qIG7o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "96Q1QO9zFqvq",
        "outputId": "ac4a4e64-c14d-4bef-9222-3c2a1b99b724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: asyncpraw in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: aiofiles<1 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.8.0)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (3.10.1)\n",
            "Requirement already satisfied: aiosqlite<=0.17.0 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.17.0)\n",
            "Requirement already satisfied: asyncprawcore<3,>=2.1 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (2.4.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.18.0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (4.0.3)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update-checker>=0.18->asyncpraw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "# Install Required Libraries:\n",
        "!pip install asyncpraw pandas nest_asyncio\n",
        "\n",
        "# Install required libraries:\n",
        "import asyncio\n",
        "import asyncpraw\n",
        "import pandas as pd\n",
        "import nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow nested event loops in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Reddit API credentials\n",
        "client_id = '_mEvCBQLeRsUrN5nmdcD6A'\n",
        "client_secret = 'ezp0D4hfMPO_jD2Sdd7xX16T_YKXvQ'\n",
        "user_agent = 'Confident-Ad8604'\n",
        "\n",
        "# Initialize async PRAW with API credentials\n",
        "reddit = asyncpraw.Reddit(client_id=client_id,\n",
        "                          client_secret=client_secret,\n",
        "                          user_agent=user_agent)\n",
        "\n",
        "# Define the subreddit and the number of posts to fetch\n",
        "subreddit_name = 'ecommercemarketing'\n",
        "num_posts = 1000\n",
        "\n",
        "async def fetch_posts():\n",
        "    subreddit = await reddit.subreddit(subreddit_name)\n",
        "    posts = []\n",
        "    async for post in subreddit.hot(limit=num_posts):\n",
        "        posts.append({\n",
        "            'title': post.title,\n",
        "            'score': post.score,\n",
        "            'id': post.id,\n",
        "            'url': post.url,\n",
        "            'num_comments': post.num_comments,\n",
        "            'created': post.created,\n",
        "            'body': post.selftext\n",
        "        })\n",
        "\n",
        "    # Convert the list of posts to a DataFrame\n",
        "    df = pd.DataFrame(posts)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    df.to_csv('/content/drive/MyDrive/Data Wrangling and Social Media Analytics Practice/reddit_posts.csv', index=False)\n",
        "\n",
        "    print(\"Posts have been saved to reddit_posts.csv\")\n",
        "\n",
        "# Run the async function\n",
        "await fetch_posts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4zd3G38bfcz",
        "outputId": "f6e36fcb-23fa-401f-cd39-e924330e62ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posts have been saved to reddit_posts.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Load the saved CSV file into a Pandas DataFrame and display the first few rows. Explain how you verified that the data was correctly saved and loaded."
      ],
      "metadata": {
        "id": "YNiZnKVJICMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data Wrangling and Social Media Analytics Practice/reddit_posts.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"First few rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Print the number of rows and columns of the DataFrame\n",
        "print(\"\\nNumber of rows and columns in the DataFrame:\", df.shape)\n",
        "\n",
        "# Print the column names of the DataFrame\n",
        "print(\"\\nColumn names of the DataFrame:\", df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If973cblIDO-",
        "outputId": "74f88fb3-8b87-409c-d588-b384fbbff88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the DataFrame:\n",
            "                                               title  score       id  \\\n",
            "0                Ask Anything Monday - Weekly Thread      3  1epzfah   \n",
            "1                      How did you all learn python?     51  1eq0hkx   \n",
            "2  How much better is Pandas actually, and is it ...     91  1eplz5d   \n",
            "3  How to get (and make sense of) Python objects'...      2  1eq8hzk   \n",
            "4    What can I do to have written this code better?      2  1eq7ua7   \n",
            "\n",
            "                                                 url  num_comments  \\\n",
            "0  https://www.reddit.com/r/learnpython/comments/...             4   \n",
            "1  https://www.reddit.com/r/learnpython/comments/...            65   \n",
            "2  https://www.reddit.com/r/learnpython/comments/...            44   \n",
            "3  https://www.reddit.com/r/learnpython/comments/...             5   \n",
            "4  https://www.reddit.com/r/learnpython/comments/...             8   \n",
            "\n",
            "        created                                               body  \n",
            "0  1.723421e+09  Welcome to another /r/learnPython weekly \"Ask ...  \n",
            "1  1.723424e+09  I'm thinking of going into Cyber Operations in...  \n",
            "2  1.723386e+09  I've been working a lot recently with gatherin...  \n",
            "3  1.723452e+09  This is about msgraph, however the question co...  \n",
            "4  1.723449e+09  I may be new to Python but I understand the fu...  \n",
            "\n",
            "Number of rows and columns in the DataFrame: (972, 7)\n",
            "\n",
            "Column names of the DataFrame: ['title', 'score', 'id', 'url', 'num_comments', 'created', 'body']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 2: Preprocessing and Cleaning**"
      ],
      "metadata": {
        "id": "u9cl8MzAF5Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdcvg6jiUEH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Handle Missing Values:** Identify any missing values in the DataFrame. Describe different strategies for handling missing data and choose one to apply to your DataFrame. Justify your choice.\n",
        "- **Identification:** Check for missing values in the DataFrame using the `isnull().sum()` method.\n",
        "- **Strategies:** Common strategies include filling missing values with a placeholder (e.g., an empty string for text data), using statistical measures (e.g., mean, median) to impute missing values, or removing rows/columns with missing data.\n",
        "- **Application:** In this example, missing values in the `body` column are filled with an empty string, and rows with missing values in the `title` or `created` columns are removed. This approach ensures that the key textual and timestamp data is complete."
      ],
      "metadata": {
        "id": "tnbxgtFoIBXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data Wrangling and Social Media Analytics Practice/reddit_posts.csv')"
      ],
      "metadata": {
        "id": "_UrBy37O9bCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values:\n",
        "\n",
        "# Check missing values before handling\n",
        "print(\"Missing values before handling:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill missing values in 'body' with an empty string\n",
        "df['body'].fillna('', inplace=True)\n",
        "\n",
        "# Remove rows with missing values in 'title' or 'created'\n",
        "df.dropna(subset=['title', 'created'], inplace=True)\n",
        "\n",
        "# Display results:\n",
        "print(\"Missing values after cleaning:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmyfivXCF5q4",
        "outputId": "73aef8b5-e480-44c6-898b-38c5fbad4fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before handling:\n",
            " title           0\n",
            "score           0\n",
            "id              0\n",
            "url             0\n",
            "num_comments    0\n",
            "created         0\n",
            "body            0\n",
            "dtype: int64\n",
            "Missing values after cleaning:\n",
            " title           0\n",
            "score           0\n",
            "id              0\n",
            "url             0\n",
            "num_comments    0\n",
            "created         0\n",
            "body            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results:** No missing values."
      ],
      "metadata": {
        "id": "40zY6DD5dr3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Remove Duplicates:** Explain why it is important to remove duplicate entries in a dataset. Write a method to identify and remove duplicates based on the `id` column. Verify that duplicates have been removed.\n",
        "- **Importance:** Duplicate entries can skew analysis results, leading to inaccurate conclusions. It is essential to ensure each record in the dataset is unique.\n",
        "- **Method:** The `drop_duplicates()` method is used to remove duplicate entries based on the `id` column, ensuring that each post is represented only once in the DataFrame.\n",
        "- **Verification:** After removing duplicates, the first few rows of the DataFrame are displayed to verify the operation."
      ],
      "metadata": {
        "id": "3jEvLBMYXlaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display number of rows and sample data before removing duplicates\n",
        "print(\"Number of rows before removing duplicates:\", len(df))\n",
        "\n",
        "# Remove duplicate entries based on 'id'\n",
        "df.drop_duplicates(subset=['id'], inplace=True)\n",
        "\n",
        "# Display number of rows and sample data after removing duplicates\n",
        "print(\"Number of rows after removing duplicates:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbahKTytXnza",
        "outputId": "6e271de2-a591-4036-bcf5-c24f1ff2182e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows before removing duplicates: 972\n",
            "Number of rows after removing duplicates: 972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results:** No duplicates."
      ],
      "metadata": {
        "id": "LTIFbzDGd0BR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Standardize Text Data:** Discuss the importance of text standardization in data preprocessing. Convert all text in the `title` and `body` columns to lowercase. Explain any other text preprocessing steps you think are necessary and apply them.\n",
        "- **Importance:** Standardizing text data (e.g., converting to lowercase) ensures consistency and improves the accuracy of text-based analysis, such as word frequency counts and text matching.\n",
        "- **Application:** The `str.lower()` method is applied to convert all text in the `title` and `body` columns to lowercase. This step is crucial for consistent text processing and analysis.\n"
      ],
      "metadata": {
        "id": "eObXbOp2Xvkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample data before text standardization\n",
        "print(\"Sample data before text standardization:\\n\", df[['title', 'body']].head())\n",
        "\n",
        "# Standardize text data\n",
        "df['title'] = df['title'].str.lower()\n",
        "df['body'] = df['body'].str.lower()\n",
        "\n",
        "# Display sample data after text standardization\n",
        "print(\"\\nSample data after text standardization:\\n\", df[['title', 'body']].head())\n",
        "\n",
        "# Show a comparison between the first entry before and after standardization for better clarity\n",
        "original_titles = df['title'].head()\n",
        "original_bodies = df['body'].head()\n",
        "\n",
        "print(\"\\nComparison of text standardization:\")\n",
        "for i in range(len(original_titles)):\n",
        "    print(f\"Original title: {original_titles.iloc[i]}\")\n",
        "    print(f\"Standardized title: {original_titles.iloc[i]}\")\n",
        "    print(f\"Original body: {original_bodies.iloc[i]}\")\n",
        "    print(f\"Standardized body: {original_bodies.iloc[i]}\")\n",
        "    print(\"---------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvyKPJykYJQC",
        "outputId": "2f6098ad-ba4b-4afd-8ce3-f9fa56af6abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data before text standardization:\n",
            "                                                title  \\\n",
            "0                Ask Anything Monday - Weekly Thread   \n",
            "1                      How did you all learn python?   \n",
            "2  How much better is Pandas actually, and is it ...   \n",
            "3  How to get (and make sense of) Python objects'...   \n",
            "4    What can I do to have written this code better?   \n",
            "\n",
            "                                                body  \n",
            "0  Welcome to another /r/learnPython weekly \"Ask ...  \n",
            "1  I'm thinking of going into Cyber Operations in...  \n",
            "2  I've been working a lot recently with gatherin...  \n",
            "3  This is about msgraph, however the question co...  \n",
            "4  I may be new to Python but I understand the fu...  \n",
            "\n",
            "Sample data after text standardization:\n",
            "                                                title  \\\n",
            "0                ask anything monday - weekly thread   \n",
            "1                      how did you all learn python?   \n",
            "2  how much better is pandas actually, and is it ...   \n",
            "3  how to get (and make sense of) python objects'...   \n",
            "4    what can i do to have written this code better?   \n",
            "\n",
            "                                                body  \n",
            "0  welcome to another /r/learnpython weekly \"ask ...  \n",
            "1  i'm thinking of going into cyber operations in...  \n",
            "2  i've been working a lot recently with gatherin...  \n",
            "3  this is about msgraph, however the question co...  \n",
            "4  i may be new to python but i understand the fu...  \n",
            "\n",
            "Comparison of text standardization:\n",
            "Original title: ask anything monday - weekly thread\n",
            "Standardized title: ask anything monday - weekly thread\n",
            "Original body: welcome to another /r/learnpython weekly \"ask anything\\* monday\" thread\n",
            "\n",
            "here you can ask all the questions that you wanted to ask but didn't feel like making a new thread.\n",
            "\n",
            "\\* it's primarily intended for simple questions but as long as it's about python it's allowed.\n",
            "\n",
            "if you have any suggestions or questions about this thread use the message the moderators button in the sidebar.\n",
            "\n",
            "**rules:**\n",
            "\n",
            "* don't downvote stuff - instead explain what's wrong with the comment, if it's against the rules \"report\" it and it will be dealt with.\n",
            "* don't post stuff that doesn't have absolutely anything to do with python.\n",
            "* don't make fun of someone for not knowing something, insult anyone etc - this will result in an immediate ban.\n",
            "\n",
            "that's it.\n",
            "Standardized body: welcome to another /r/learnpython weekly \"ask anything\\* monday\" thread\n",
            "\n",
            "here you can ask all the questions that you wanted to ask but didn't feel like making a new thread.\n",
            "\n",
            "\\* it's primarily intended for simple questions but as long as it's about python it's allowed.\n",
            "\n",
            "if you have any suggestions or questions about this thread use the message the moderators button in the sidebar.\n",
            "\n",
            "**rules:**\n",
            "\n",
            "* don't downvote stuff - instead explain what's wrong with the comment, if it's against the rules \"report\" it and it will be dealt with.\n",
            "* don't post stuff that doesn't have absolutely anything to do with python.\n",
            "* don't make fun of someone for not knowing something, insult anyone etc - this will result in an immediate ban.\n",
            "\n",
            "that's it.\n",
            "---------\n",
            "Original title: how did you all learn python?\n",
            "Standardized title: how did you all learn python?\n",
            "Original body: i'm thinking of going into cyber operations in the military and i figured i'd finally start learning python (i've been procrastinating it for a while). how did you all learn python? i have python and pycharm installed on my pc, and i'm thinking i'll just find a series on youtube and go from there. any advice?\n",
            "Standardized body: i'm thinking of going into cyber operations in the military and i figured i'd finally start learning python (i've been procrastinating it for a while). how did you all learn python? i have python and pycharm installed on my pc, and i'm thinking i'll just find a series on youtube and go from there. any advice?\n",
            "---------\n",
            "Original title: how much better is pandas actually, and is it detrimental to not be implementing it?\n",
            "Standardized title: how much better is pandas actually, and is it detrimental to not be implementing it?\n",
            "Original body: i've been working a lot recently with gathering and filtering/cleaning data in python at work and have been trying to add pandas to what i'm doing, but always end up going back to pure python. most of what i'm working with is data that i've pulled from somewhere online (usually rest services or through the arcgis module we use a lot), which gets built into a list of dictionaries with all the values i'm interested in. once i get everything, i usually have some sort of filter or data manipulation i want to do before saving my data to a file which is where pandas would be useful, but the syntax confuses me so much it's genuinely just faster to write out something in pure python to drop records and/or format my data. \n",
            "\n",
            "so really, am i missing out on much by not implementing it into what i'm doing? the biggest thing for me is the speed since i don't have an issue writing out a solution without pandas, but if i eventually end up working with larger and larger datasets, is there much of a different in other aspects that i should worry about?\n",
            "Standardized body: i've been working a lot recently with gathering and filtering/cleaning data in python at work and have been trying to add pandas to what i'm doing, but always end up going back to pure python. most of what i'm working with is data that i've pulled from somewhere online (usually rest services or through the arcgis module we use a lot), which gets built into a list of dictionaries with all the values i'm interested in. once i get everything, i usually have some sort of filter or data manipulation i want to do before saving my data to a file which is where pandas would be useful, but the syntax confuses me so much it's genuinely just faster to write out something in pure python to drop records and/or format my data. \n",
            "\n",
            "so really, am i missing out on much by not implementing it into what i'm doing? the biggest thing for me is the speed since i don't have an issue writing out a solution without pandas, but if i eventually end up working with larger and larger datasets, is there much of a different in other aspects that i should worry about?\n",
            "---------\n",
            "Original title: how to get (and make sense of) python objects' attributes and methods?\n",
            "Standardized title: how to get (and make sense of) python objects' attributes and methods?\n",
            "Original body: this is about msgraph, however the question could be general as well.\n",
            "\n",
            "so i am doing this:\n",
            "\n",
            "    from msgraph import graphserviceclient\n",
            "    \n",
            "    client = graphserviceclient(credentials=credential, scopes=scopes)\n",
            "\n",
            "  \n",
            "now i am trying to find out what attributes and methods has client object. and end goal is to see what i can do with this object. \n",
            "\n",
            "i've tried to print it and pprint. all it gives is a reference to the object in memory. \n",
            "\n",
            "so, how do you work with this object now?\n",
            "Standardized body: this is about msgraph, however the question could be general as well.\n",
            "\n",
            "so i am doing this:\n",
            "\n",
            "    from msgraph import graphserviceclient\n",
            "    \n",
            "    client = graphserviceclient(credentials=credential, scopes=scopes)\n",
            "\n",
            "  \n",
            "now i am trying to find out what attributes and methods has client object. and end goal is to see what i can do with this object. \n",
            "\n",
            "i've tried to print it and pprint. all it gives is a reference to the object in memory. \n",
            "\n",
            "so, how do you work with this object now?\n",
            "---------\n",
            "Original title: what can i do to have written this code better?\n",
            "Standardized title: what can i do to have written this code better?\n",
            "Original body: i may be new to python but i understand the fundamentals of programming (to an extent). how could i have written this code block better? i'm pretty sure my use of global variables is not the way i should be doing this...\n",
            "\n",
            "    user_name = \"fred\"\n",
            "    saved_pin = \"1245\"\n",
            "    balance = 1000\n",
            "    credentials = false\n",
            "    input_name = \"\"\n",
            "    input_pin = \"\"\n",
            "    \n",
            "    def main():\n",
            "        check_credentials()\n",
            "        main_menu()\n",
            "        chosen_option()\n",
            "        \n",
            "    def check_credentials():\n",
            "        global credentials\n",
            "        while credentials == false:\n",
            "            input_name = input(\"user name:\")\n",
            "            input_pin = input(\"pin: \")\n",
            "            if input_name == user_name:\n",
            "                if input_pin == saved_pin:\n",
            "                    #print(\"you're in!\")\n",
            "                    credentials = true\n",
            "                else:\n",
            "                    print(\"we don't recognize this info. try again.\")\n",
            "            else:\n",
            "                print(\"we don't recognize this info. try again.\")\n",
            "        return\n",
            "        \n",
            "    def main_menu():\n",
            "        print(\"welcome to chase bank atm. please select your desired option.\")\n",
            "        print(\"1. check balance | 2. cash deposit | 3. cash withdraw | 4. exit\")\n",
            "        \n",
            "    def chosen_option():\n",
            "        global balance\n",
            "        choice = input(\"desired option: \")\n",
            "        while true:\n",
            "            if choice == \"1\":\n",
            "                print(\"your current balnace is\", balance)\n",
            "            elif choice == \"2\":\n",
            "                deposit()\n",
            "            elif choice == \"3\":\n",
            "                withdraw()\n",
            "            elif choice == \"4\":\n",
            "                print(\"thank you for visiting chase bank.\")\n",
            "                break\n",
            "            else:\n",
            "                print(\"invalid option\")\n",
            "                print(\"1. check balance | 2. cash deposit | 3. cash withdraw | 4. exit\")\n",
            "                \n",
            "            choice = input(\"desired option: \")\n",
            "        \n",
            "    def deposit():\n",
            "        global balance\n",
            "        deposit_amount = int(input(\"enter amount to deposit: \"))\n",
            "        balance = balance + deposit_amount\n",
            "        print(\"new balance: \", balance)\n",
            "        return\n",
            "        \n",
            "    def withdraw():\n",
            "        global balance\n",
            "        withdraw_amount = int(input(\"enter amount to withdrawal: \"))\n",
            "        balance = balance - withdraw_amount\n",
            "        print(\"new balance: \", balance)\n",
            "        return\n",
            "                    \n",
            "    main()\n",
            "Standardized body: i may be new to python but i understand the fundamentals of programming (to an extent). how could i have written this code block better? i'm pretty sure my use of global variables is not the way i should be doing this...\n",
            "\n",
            "    user_name = \"fred\"\n",
            "    saved_pin = \"1245\"\n",
            "    balance = 1000\n",
            "    credentials = false\n",
            "    input_name = \"\"\n",
            "    input_pin = \"\"\n",
            "    \n",
            "    def main():\n",
            "        check_credentials()\n",
            "        main_menu()\n",
            "        chosen_option()\n",
            "        \n",
            "    def check_credentials():\n",
            "        global credentials\n",
            "        while credentials == false:\n",
            "            input_name = input(\"user name:\")\n",
            "            input_pin = input(\"pin: \")\n",
            "            if input_name == user_name:\n",
            "                if input_pin == saved_pin:\n",
            "                    #print(\"you're in!\")\n",
            "                    credentials = true\n",
            "                else:\n",
            "                    print(\"we don't recognize this info. try again.\")\n",
            "            else:\n",
            "                print(\"we don't recognize this info. try again.\")\n",
            "        return\n",
            "        \n",
            "    def main_menu():\n",
            "        print(\"welcome to chase bank atm. please select your desired option.\")\n",
            "        print(\"1. check balance | 2. cash deposit | 3. cash withdraw | 4. exit\")\n",
            "        \n",
            "    def chosen_option():\n",
            "        global balance\n",
            "        choice = input(\"desired option: \")\n",
            "        while true:\n",
            "            if choice == \"1\":\n",
            "                print(\"your current balnace is\", balance)\n",
            "            elif choice == \"2\":\n",
            "                deposit()\n",
            "            elif choice == \"3\":\n",
            "                withdraw()\n",
            "            elif choice == \"4\":\n",
            "                print(\"thank you for visiting chase bank.\")\n",
            "                break\n",
            "            else:\n",
            "                print(\"invalid option\")\n",
            "                print(\"1. check balance | 2. cash deposit | 3. cash withdraw | 4. exit\")\n",
            "                \n",
            "            choice = input(\"desired option: \")\n",
            "        \n",
            "    def deposit():\n",
            "        global balance\n",
            "        deposit_amount = int(input(\"enter amount to deposit: \"))\n",
            "        balance = balance + deposit_amount\n",
            "        print(\"new balance: \", balance)\n",
            "        return\n",
            "        \n",
            "    def withdraw():\n",
            "        global balance\n",
            "        withdraw_amount = int(input(\"enter amount to withdrawal: \"))\n",
            "        balance = balance - withdraw_amount\n",
            "        print(\"new balance: \", balance)\n",
            "        return\n",
            "                    \n",
            "    main()\n",
            "---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results:** Standadized data"
      ],
      "metadata": {
        "id": "g5wE4tkNd5-N"
      }
    }
  ]
}